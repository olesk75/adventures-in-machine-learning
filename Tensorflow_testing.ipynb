{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvdAqkIRrsjnrAYo21MjKH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olesk75/adventures-in-machine-learning/blob/main/Tensorflow_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BojWgpZDrf1p"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKMee3eWqoMu"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ooOVeEzuI3X",
        "outputId": "e87e22d3-019f-44b3-c591-67cf18a8d7b7"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9HofWNGysrt"
      },
      "source": [
        "Initial hello world equivalent - single node network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5mI4MK2yilg"
      },
      "source": [
        "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIyJCgb5y_XA"
      },
      "source": [
        "The *loss* function determines how big the error is.\n",
        "The *optimizer* function picks the next guess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBynBPpfyrtE"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrN_O4P_u-WK"
      },
      "source": [
        "# The famous MNIST dataset of 28x28 images hand-written digits (0-9)\n",
        "mnist = tf.keras.datasets.mnist"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIDEwcNKvHsY"
      },
      "source": [
        "# x_train, x_test: uint8 28x28 arrays of grayscale image data with shapes (num_samples, 28, 28).\n",
        "# y_train, y_test: uint8 arrays of digit labels (integers in range 0-9) with shapes (num_samples,).\n",
        " \n",
        " \n",
        " # First training data, then test data\n",
        " # Training data is essentially example hand-written digits (x_train) in image arrays,\n",
        " # and which number each image corresponds to in the y_train array.\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# We have 0-255 values and need 0.0-1.0 so we normalize\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-pfS8apqxjl",
        "outputId": "6354443b-55e6-45da-bf6c-56b32be3515f"
      },
      "source": [
        "#\n",
        "# MODEL CONSTRUCTION\n",
        "#\n",
        "\n",
        "# Sequential means we have a feedforward neural network (connections between the nodes do not form a cycle)\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Adds a model that reduces 28x28 2D arrays to single 1D array in out INPUT layer\n",
        "# (we could've used numpy or anything else for this)\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# densely-connected NN layer with 128 neurons in a layer\n",
        "# activation function is the function that makes the layer fire\n",
        "# tf.nn.relu is the standard default activation function\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "\n",
        "# densely-connected NN layer with 128 neurons in a layer\n",
        "# activation function is the function that makes the layer fire\n",
        "# tf.nn.relu is the standard default activation function\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "\n",
        "# densely-connected OUTPUT layer with 128 neurons in a layer\n",
        "# activation function is the function that makes the layer fire\n",
        "# tf.nn.relu is the standard default activation function\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "# Note that the NN will always optmize for minimum loss\n",
        "# adam is the default go-to optimizer\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
        "\n",
        "# Running the model three times\n",
        "model.fit(x_train, y_train, epochs=3)\n",
        "\n",
        "# As the model could overfit (just memorize every sample instead of creating general rules), we must check\n",
        "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f'Evaluated loss: {val_loss}\\nEvaluated accuracy: {val_acc}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4599 - accuracy: 0.8648\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1119 - accuracy: 0.9658\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0696 - accuracy: 0.9779\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9717\n",
            "Evaluated loss: 0.09077392518520355\n",
            "Evaluated accuracy: 0.9717000126838684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e6sQh8kvcAn",
        "outputId": "55391bb0-5bf3-4a5d-d36b-5dd4193df392"
      },
      "source": [
        "# Here we save the trained model\n",
        "model.save('basic_tester_mnist.model')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: basic_tester_mnist.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CuCudqjvSd2",
        "outputId": "b36fade7-7585-4b69-aeb1-c18d29870399"
      },
      "source": [
        "# Then, for testing, we load the  trained model\n",
        "new_model = tf.keras.models.load_model('basic_tester_mnist.model')\n",
        "\n",
        "# We now use the model we loaded back in to find predictions for the sample dataset x_test\n",
        "# Returns array for each element with predictions for each digit (0-9)\n",
        "predictions = new_model.predict(x_test)\n",
        "\n",
        "# Finding the strongest prediction for the second element (a badly written 2)\n",
        "best_match = np.argmax(predictions[1])\n",
        "\n",
        "print(f'Best match for our badly written 2 is: {best_match}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best match for our badly written 2 is: 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}